# ============================================================================
# SHADOWCHECK POSTGRESQL 18 PERFORMANCE CONFIGURATION
# Optimized for SIGINT data ingestion and PostGIS spatial queries
# ============================================================================
#
# POSTGRESQL 18 NEW FEATURES ENABLED:
# - Enhanced parallel query execution for spatial operations
# - Improved BRIN indexes for time-series data
# - Better JSON/JSONB performance for raw_data field
# - Optimized GiST indexes for spatial queries
# - Enhanced autovacuum for high-insert workloads
#
# ============================================================================

# ----------------------------------------------------------------------------
# CONNECTION SETTINGS
# ----------------------------------------------------------------------------
max_connections = 100
superuser_reserved_connections = 3

# ----------------------------------------------------------------------------
# MEMORY SETTINGS (Tuned for SIGINT data workload)
# ----------------------------------------------------------------------------
# Shared buffers - 25% of available RAM for dedicated DB server
shared_buffers = 512MB

# Effective cache size - estimate of OS + PostgreSQL cache
# Set to ~75% of system RAM
effective_cache_size = 1GB

# Work memory - per-operation memory for sorting/hashing
# Important for spatial operations and aggregations
work_mem = 16MB

# Maintenance work memory - for VACUUM, CREATE INDEX, etc.
# Critical for PostGIS index creation
maintenance_work_mem = 256MB

# Hash memory - for hash joins (new in PG18)
hash_mem_multiplier = 2.0

# ----------------------------------------------------------------------------
# QUERY PLANNING (PostgreSQL 18 enhancements)
# ----------------------------------------------------------------------------
# Cost estimates for SSD storage
random_page_cost = 1.1
seq_page_cost = 1.0

# Parallel query execution (enhanced in PG18)
max_parallel_workers_per_gather = 4
max_parallel_maintenance_workers = 4
max_parallel_workers = 8
parallel_tuple_cost = 0.05  # Lower cost for parallel operations
parallel_setup_cost = 500

# Effective I/O concurrency for NVMe SSDs
effective_io_concurrency = 200

# Enable JIT compilation for complex queries (improved in PG18)
jit = on
jit_above_cost = 100000
jit_inline_above_cost = 500000
jit_optimize_above_cost = 500000

# ----------------------------------------------------------------------------
# WRITE-AHEAD LOG (WAL) SETTINGS
# ----------------------------------------------------------------------------
wal_level = replica
wal_buffers = 16MB
min_wal_size = 1GB
max_wal_size = 4GB

# WAL compression (enhanced in PG18)
wal_compression = lz4

# Full page writes (required for crash recovery)
full_page_writes = on

# WAL writer delay
wal_writer_delay = 200ms

# ----------------------------------------------------------------------------
# CHECKPOINT SETTINGS
# ----------------------------------------------------------------------------
checkpoint_completion_target = 0.9
checkpoint_timeout = 15min
checkpoint_warning = 30s

# ----------------------------------------------------------------------------
# AUTOVACUUM SETTINGS (Critical for high-insert SIGINT data)
# ----------------------------------------------------------------------------
autovacuum = on
autovacuum_max_workers = 4
autovacuum_naptime = 10s

# Aggressive autovacuum for signal_detections table
autovacuum_vacuum_threshold = 50
autovacuum_analyze_threshold = 50
autovacuum_vacuum_scale_factor = 0.05
autovacuum_analyze_scale_factor = 0.02

# Vacuum cost settings (prevent I/O starvation)
autovacuum_vacuum_cost_delay = 10ms
autovacuum_vacuum_cost_limit = 1000

# ----------------------------------------------------------------------------
# LOGGING SETTINGS
# ----------------------------------------------------------------------------
logging_collector = on
log_directory = 'log'
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
log_file_mode = 0600

# Rotation
log_rotation_age = 1d
log_rotation_size = 100MB
log_truncate_on_rotation = on

# What to log
log_min_duration_statement = 1000  # Log queries slower than 1s
log_line_prefix = '%t [%p] %u@%d [%a] '
log_checkpoints = on
log_connections = on
log_disconnections = on
log_duration = off
log_lock_waits = on  # Log lock waits > deadlock_timeout
log_statement = 'ddl'  # Log all DDL statements
log_temp_files = 0  # Log all temp files

# ----------------------------------------------------------------------------
# LOCK MANAGEMENT (Important for PostGIS)
# ----------------------------------------------------------------------------
max_locks_per_transaction = 256  # Higher for PostGIS operations
max_pred_locks_per_transaction = 256
deadlock_timeout = 1s

# ----------------------------------------------------------------------------
# STATEMENT TIMEOUT (Prevent runaway queries)
# ----------------------------------------------------------------------------
statement_timeout = 30000  # 30 seconds
idle_in_transaction_session_timeout = 60000  # 1 minute

# ----------------------------------------------------------------------------
# CLIENT CONNECTION DEFAULTS
# ----------------------------------------------------------------------------
# Locale and formatting
datestyle = 'iso, mdy'
timezone = 'UTC'
lc_messages = 'en_US.UTF-8'
lc_monetary = 'en_US.UTF-8'
lc_numeric = 'en_US.UTF-8'
lc_time = 'en_US.UTF-8'

# Default text search configuration
default_text_search_config = 'pg_catalog.english'

# ----------------------------------------------------------------------------
# POSTGIS-SPECIFIC SETTINGS
# ----------------------------------------------------------------------------
# Increase for complex spatial operations
max_locks_per_transaction = 256

# Enable parallel PostGIS operations (PG18 enhancement)
postgis.enable_outdb_rasters = false
postgis.gdal_enabled_drivers = 'ENABLE_ALL'

# ----------------------------------------------------------------------------
# BACKGROUND WRITER (Tuned for high-insert workload)
# ----------------------------------------------------------------------------
bgwriter_delay = 200ms
bgwriter_lru_maxpages = 100
bgwriter_lru_multiplier = 2.0
bgwriter_flush_after = 512kB

# ----------------------------------------------------------------------------
# ASYNC COMMIT (Use with caution - trades durability for performance)
# ----------------------------------------------------------------------------
# For SIGINT data where some data loss is acceptable:
# synchronous_commit = off  # Uncomment for 10x write performance

# ----------------------------------------------------------------------------
# TABLE STATISTICS (Enhanced in PG18)
# ----------------------------------------------------------------------------
default_statistics_target = 100  # Higher for complex queries
track_activities = on
track_counts = on
track_io_timing = on
track_functions = all

# ----------------------------------------------------------------------------
# POSTGRESQL 18 SPECIFIC OPTIMIZATIONS
# ----------------------------------------------------------------------------
# Enhanced incremental sort
enable_incremental_sort = on

# Memoization (caching) for repeated subquery results
enable_memoize = on

# Partition-wise join and aggregate
enable_partitionwise_join = on
enable_partitionwise_aggregate = on

# Async append for partitioned tables
enable_async_append = on

# ----------------------------------------------------------------------------
# EXTENSIONS
# ----------------------------------------------------------------------------
shared_preload_libraries = 'pg_stat_statements'  # Query statistics

# pg_stat_statements configuration
pg_stat_statements.max = 10000
pg_stat_statements.track = all
pg_stat_statements.track_utility = on

# ============================================================================
# PERFORMANCE TUNING NOTES
# ============================================================================
#
# For even better performance with SIGINT time-series data:
#
# 1. Use BRIN indexes for detected_at (much smaller than B-tree):
#    CREATE INDEX ON signal_detections USING BRIN(detected_at);
#
# 2. Consider partitioning signal_detections by time range:
#    CREATE TABLE signal_detections (...)
#    PARTITION BY RANGE (detected_at);
#
# 3. Use parallel queries for large spatial aggregations:
#    SET max_parallel_workers_per_gather = 4;
#
# 4. Monitor with pg_stat_statements:
#    SELECT * FROM pg_stat_statements ORDER BY total_exec_time DESC LIMIT 10;
#
# ============================================================================
